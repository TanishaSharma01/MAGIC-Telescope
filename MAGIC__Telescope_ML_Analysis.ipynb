{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/TanishaSharma01/MAGIC-gamma-hadron-classification/blob/main/MAGIC__Telescope_ML_Analysis.ipynb",
      "authorship_tag": "ABX9TyOnxSNnW2PqJn8tOT9asE22",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TanishaSharma01/MAGIC-gamma-hadron-classification/blob/main/MAGIC__Telescope_ML_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBPTWO2yCp59"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import RandomOverSampler"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset:\n",
        "Bock, R. (2004). MAGIC Gamma Telescope [Dataset]. UCI Machine Learning Repository. https://doi.org/10.24432/C52C8B."
      ],
      "metadata": {
        "id": "o2Tywct3DljZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# labels for the columns\n",
        "cols = [\"fLength\", \"fWidth\", \"fSize\", \"fConc\", \"fConc1\", \"fAsym\", \"fM3Long\", \"fM3Trans\",\n",
        "        \"fAlpha\", \"fDist\", \"class\"]\n",
        "\n",
        "# read the data from our dataset\n",
        "df = pd.read_csv(\"magic04.data\", names=cols)\n",
        "\n",
        "# first 5 rows\n",
        "df.head()"
      ],
      "metadata": {
        "id": "-9Sd__U3DSmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unique data in column \"class\"\n",
        "df[\"class\"].unique()\n",
        "\n",
        "# converting the value for \"g\" to int\n",
        "# 'g' is for gamma and 'h' ias for hadron\n",
        "df[\"class\"] = (df[\"class\"] == \"g\").astype(int)"
      ],
      "metadata": {
        "id": "JHF2Z_RoGFqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "QiV-fdK5Gfmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for label in cols[:-1]:\n",
        "  plt.hist(df[df[\"class\"]==1][label], color='blue', label='gamma', alpha=0.7, density=True)\n",
        "  plt.hist(df[df[\"class\"]==0][label], color='red', label='hadron', alpha=0.7, density=True)\n",
        "  plt.title(label)\n",
        "  plt.ylabel(\"Probability\")\n",
        "  plt.xlabel(label)\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ud2WwJb3GsOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train, validation and Test Data Sets"
      ],
      "metadata": {
        "id": "kzaRwvq2vXCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting the dataset such that 60% of the data is for training\n",
        "# 0.6 marks the end of the training dataset\n",
        "# 0.8 marks the end of the validation\n",
        "train, valid, test = [pd.DataFrame(x, columns=df.columns) for x in np.split(df.sample(frac=1).values,\n",
        "                                                                            [int(0.6 * len(df)),\n",
        "                                                                             int(0.8 * len(df))])]"
      ],
      "metadata": {
        "id": "QQ-8vx1VvRa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scale_dataset(dataframe, oversample = False):\n",
        "  # labels that would be our inputs, that is we get all the columns except the last\n",
        "  X = dataframe[dataframe.columns[:-1]].values\n",
        "\n",
        "  # label that is the output/target that is the last column\n",
        "  y = dataframe[dataframe.columns[-1]].values\n",
        "\n",
        "  # normalizes the feature matrix X\n",
        "  # fit() - Calculates the mean and standard deviation for each feature column\n",
        "  # transform() - Applies the standardization using those calculated statistics\n",
        "  scaler = StandardScaler()\n",
        "  X =  scaler.fit_transform(X)\n",
        "\n",
        "  if oversample:\n",
        "    ros = RandomOverSampler()\n",
        "    X, y = ros.fit_resample(X, y)\n",
        "\n",
        "  # horizontally stack them together\n",
        "  # here X is 2-D but y is 1-D\n",
        "  # we reshape y to be a column vector\n",
        "  data = np.hstack((X, np.reshape(y, (-1, 1))))\n",
        "\n",
        "  return data, X, y"
      ],
      "metadata": {
        "id": "nWey0uYe6cxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gamma values are disproportionately more than hadron\n",
        "print(len(train[train[\"class\"] == 1])) #gamma\n",
        "print(len(train[train[\"class\"] == 0])) #hadron"
      ],
      "metadata": {
        "id": "G0pO8ItS9lL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to evenly rebalance number of gammas and hadrons\n",
        "train, X_train, y_train = scale_dataset(train, oversample = True)\n",
        "valid, X_valid, y_valid = scale_dataset(valid, oversample = False)\n",
        "test, X_test, y_test = scale_dataset(test, oversample = False)\n",
        "\n",
        "print(len(y_train))\n",
        "print(sum(y_train == 1))\n",
        "print(sum(y_train == 0))"
      ],
      "metadata": {
        "id": "fU49sFmpCN28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# kNN: K nearest neighbours"
      ],
      "metadata": {
        "id": "LTxRJMWjxGpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "DMQdq1tUD9mP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn_model = KNeighborsClassifier(n_neighbors=11)\n",
        "knn_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "m49dcKhQxdTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = knn_model.predict(X_test)"
      ],
      "metadata": {
        "id": "vO7uZ0NWyavP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Precision: Out of all of the values we predicted, how many of our predicted values are right\n",
        "\n",
        "Recall: Out of all the values of a specific classification type, how many of our predicted values are right\n",
        "\n",
        "F1-score: combination of two\n",
        "\n",
        "Accuracy: how accurate our model is"
      ],
      "metadata": {
        "id": "KKZLn6JZzf9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "bvWmV9UhynXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes"
      ],
      "metadata": {
        "id": "LoQA1QasbYK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "metadata": {
        "id": "ddl-2KdhypdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_model = GaussianNB()\n",
        "nb_model = nb_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "rRNws9YZysev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = nb_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "w3u7n9-gb1Zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression"
      ],
      "metadata": {
        "id": "PnsZ3kZUxx6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "vAoWGLNCcBiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lg_model = LogisticRegression()\n",
        "lg_model = lg_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "SoOhoXeJcFmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = lg_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "TUhfEcIzyC98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Support Vector Machine (SVM)"
      ],
      "metadata": {
        "id": "9aDKLoMugvpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "rKVknOLmyIKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_model = SVC()\n",
        "svm_model = svm_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "6_jxegNrhChc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = svm_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "ET42JECnhOpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural Net"
      ],
      "metadata": {
        "id": "7ZOTdAB5hYGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "TKkIwCJ75beM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "smeu78X35fR3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}